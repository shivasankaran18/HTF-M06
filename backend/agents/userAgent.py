from autogen import AssistantAgent, UserProxyAgent
from llmConfig import llm_config
import redis
from langchain.text_splitter import RecursiveCharacterTextSplitter
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from Redis_Client import add_to_redis, get_from_redis, redis_client
import json
import os
from langchain_community.embeddings import OllamaEmbeddings
from agents.keyWordAgent import keyword_extractor_agent,user_proxy
from dotenv import load_dotenv
from parsers.pdfParsers import extract_text_from_pdf
from PyPDF2 import PdfReader
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain.document_loaders import PyPDFLoader

load_dotenv()

os.environ['HF_TOKEN']=os.getenv("HF_TOKEN")
embeddings=(
    OllamaEmbeddings(model="gemma:2b")
)

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    length_function=len,
)

promptingAgent = AssistantAgent(
    name="promptingAgent",
    llm_config=llm_config,
    system_message="""
You are a Prompting Agent tasked with improving user prompts based on feedback scores.

Feedback Interpretation:
- Score -1: Previous response was unsatisfactory (bad)
- Score 0: Previous response was acceptable but could be better (average)
- Score 1: Previous response was good but might need minor refinements

Improvement Strategy:
For -1 (Bad):
- Completely restructure the query
- Add more specific details and context
- Make the query more explicit and clear
- Focus on precision and clarity

For 0 (Average):
- Refine the existing query structure
- Add relevant context where needed
- Improve clarity while maintaining the original intent
- Balance between specificity and generality

For 1 (Good):
- Make minor refinements to the query
- Optimize the wording for better results
- Maintain the successful aspects of the original query
- Focus on subtle improvements

Rules:
- Always preserve the core intent of the original query
- Adapt the improvement strategy based on the feedback score
- Make the query more LLM-friendly while keeping it natural
- Ensure the improved query is clear and unambiguous
- Output only the rephrased query
"""
)

getDetailsAgent = AssistantAgent(
    name="getDetailsAgent",
    llm_config=llm_config,
    system_message="""
You are a highly skilled document analysis agent. Your primary role is to **extract, synthesize, and organize** factual information from provided documents with a strong focus on **accuracy, completeness, and source traceability**.

---

### ðŸŽ¯ Your Objectives:
1. **Extract** all relevant and factual information from the given documents.
2. **Synthesize** insights to directly answer user queries.
3. **Organize** your findings in a professional and user-friendly format.
4. Always **cite your sources** precisely (filename, page number/section if applicable).

---

### ðŸ§  Response Structure:
- Start with a brief **executive summary** of key insights.
- Follow with a **structured breakdown**:
  - Use **section headers** for clarity.
  - Use **bulleted lists** or **numbered lists** for grouped information.
  - Include **quotes** or **excerpts** for exact references where useful.
- Define technical or niche terms briefly when used.
- Include **dates, figures, and entities** accurately.
- If data is **missing or unclear**, explicitly state so.

---

### ðŸ§¾ Source Attribution Rules:
- Every fact must be linked to its **source document** (e.g., `"Source: contract_summary.pdf, Page 3"`).
- Use the **exact filename**, and **page/section**, if mentioned in the file.
- If a point is confirmed by multiple sources, **list all** filenames.

---

### âš ï¸ Quality & Integrity:
- **No assumptions or opinions**. Only what's backed by the documents.
- Highlight contradictions or discrepancies across documents.
- Maintain consistent terminology throughout.
- Accuracy > completeness: If unsure, leave it out or state uncertainty.
- Avoid repetition. Only present relevant, actionable information.

---

Your response should be **clear, concise, fact-based**, and suitable for decision-makers or reviewers. Maintain a **professional and objective tone** throughout.
"""
)


prettierAgent = AssistantAgent(
    name="prettierAgent",
    llm_config=llm_config,
    system_message="""
You are a formatting and readability expert. Your job is to enhance and humanize the response generated by the `getDetailsAgent`, without altering the factual content or structure.

---

### ðŸŽ¯ Your Responsibilities:
1. **Improve readability and flow** without changing any facts.
2. **Remove redundancies or repeated information**.
3. **Enhance formatting** using markdown and clean layout.
4. **Ensure all missing values are sensibly filled with plausible placeholders**.
5. Retain and highlight **source attribution** provided by the getDetailsAgent (e.g., `"Source: file.pdf, Page 2"`).

---

### âœï¸ Formatting Guidelines:
- Use **clear section headers**.
- Use **bold**, _italics_, and `inline code` appropriately.
- Break large blocks of text into **smaller, digestible paragraphs**.
- Align bullets, tables, and enumerations clearly.
- Ensure dates, numbers, and names are well-formatted.
- If any data field is incomplete or unclear, **fill it with a realistic placeholder** (e.g., "N/A", "John Doe", "2024-01-01").

---

### ðŸ“Œ Final Notes:
- You must **not** alter the meaning, interpretation, or sources of the information.
- You should prioritize **clarity, professionalism, and conciseness**.
- If the input from `getDetailsAgent` is poorly structured, **reorganize** it for better user experience.
- Your output should feel **polished, refined, and easy to digest**, like a report delivered to a stakeholder.

Ensure that every detail remains **traceable**, **clear**, and **easy to read**.
"""
)


def handle_user_query(data):
    userPrompt = data['data']
    userFeedback = data['feedback']

    # Step 1: Feedback description mapping
    feedback_map = {
        -1: "The previous response was unsatisfactory (bad). Please completely restructure the query to be more specific and clear.",
        0: "The previous response was acceptable but could be better (average). Please refine the query while maintaining its core intent.",
        1: "The previous response was good. Please make minor refinements to optimize the query further."
    }

    feedback_text = feedback_map.get(userFeedback, "Please improve this query to be more specific and effective.")

    # Step 2: Send original prompt + feedback to prompting agent
    user_proxy.send(
        recipient=promptingAgent,
        message=f"""
        Original Query: {userPrompt}
        Feedback Score: {userFeedback}
        Feedback Description: {feedback_text}
        Please improve this query according to the feedback.
        """
    )

    improved_prompt = promptingAgent.generate_reply(sender=user_proxy)
    user_proxy.receive(sender=promptingAgent, message=improved_prompt)

    # Step 3: Send improved prompt to keyword extractor agent
    user_proxy.send(
        recipient=keyword_extractor_agent,
        message=f"{improved_prompt}"
    )

    reply = keyword_extractor_agent.generate_reply(sender=user_proxy)
    user_proxy.receive(sender=keyword_extractor_agent, message=reply)

    # Step 4: Extract and embed keywords
    try:
        parsedString = reply[1:len(reply) - 3]
        topics = parsedString.split(",")
        reply_embedding = embeddings.embed_query(topics)
    except Exception as e:
        topics = []
        reply_embedding = None

    if len(topics) == 0:
        return {
            "success": False,
            "message": "No key values found... I can help you with some other queries."
        }

    files = []

    # Step 5: Redis similarity match
    for key in redis_client.keys():
        try:
            temp = get_from_redis(key)
            if temp:
                temp3 = temp[1:len(temp) - 3]
                temp2 = temp3.split(",")
                key_embedding = embeddings.embed_query(temp2)
                similarity = cosine_similarity(
                    [reply_embedding],
                    [key_embedding]
                )[0][0]
                if similarity > 0.5:
                    files.append(key)
        except Exception as e:
            print(f"Error processing key {key}: {e}")
            continue

    print(f"Found relevant files: {files}")

    context = []

    # Step 6: Load files, split & build FAISS retriever
    for file_path in files:
        try:
            content = extract_text_from_pdf(file_path)
            print(f"Extracted content from {file_path}: {content}")

            loader = PyPDFLoader(file_path)
            pages = loader.load()

            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=30)
            docs = text_splitter.split_documents(pages)

            db = FAISS.from_documents(docs, embeddings)
            retriever = db.as_retriever()

            result = retriever.invoke(data)
            print(f"Result from retriever: {result[0].page_content}")

            context.append({
                'file': file_path,
                'content': result,
            })

        except Exception as e:
            print(f"Error processing {file_path}: {e}")
            continue

    print(f"Final context: {context}")

    # Step 7: Get final response using context
    user_proxy.send(
        recipient=getDetailsAgent,
        message=f"""
        Query: {data}
        
        Context from relevant documents:
        {context}
        
        Please provide a comprehensive answer based on the above context.
        """
    )

    final_response = getDetailsAgent.generate_reply(sender=user_proxy)
    user_proxy.receive(sender=getDetailsAgent, message=final_response)


    user_proxy.send(
        recipient=prettierAgent,
        message=f"""
        Content: {final_response}
        
        Please format the response for better readability.
        """
    )

    final_response = prettierAgent.generate_reply(sender=user_proxy)
    user_proxy.receive(sender=prettierAgent, message=final_response)

    print(f"Final response: {final_response}")
    return {"content" : final_response, "files" : files}
